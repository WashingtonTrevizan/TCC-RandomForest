# ğŸ›¡ï¸ DDoS Detector IA - Pipeline Corrigido

Sistema de detecÃ§Ã£o de ataques DDoS em tempo real usando Random Forest com pipeline de dados padronizado e consistente.

## ğŸ“‹ O que foi corrigido

### Problemas identificados e solucionados:
1. **InconsistÃªncia nas features** entre treinamento e inferÃªncia âœ…
2. **Dados normalizados misturados** com dados originais âœ…  
3. **CÃ¡lculo incorreto de flow_duration** âœ…
4. **Mapeamento de labels inconsistente** âœ…
5. **Features nÃ£o utilizadas** no modelo âœ…
6. **Falta de validaÃ§Ã£o** de dados âœ…

## ğŸ—ï¸ Arquitetura Corrigida

```
1. PCAP â†’ CSV (dados brutos)
   â†“
2. Feature Engineering (features calculadas)
   â†“  
3. PrÃ©-processamento (normalizaÃ§Ã£o)
   â†“
4. Treinamento (modelo salvo)
   â†“
5. InferÃªncia (prediÃ§Ãµes consistentes)
```

## ğŸš€ Como usar o pipeline corrigido

### 1. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### 2. Executar pipeline completo

#### OpÃ§Ã£o A: Executar tudo de uma vez
```bash
python test_pipeline.py
```

#### OpÃ§Ã£o B: Executar passo a passo
```bash
# 1. Converter PCAP para CSV (se necessÃ¡rio)
python tools/pcap_to_csv.py

# 2. Processar dados e calcular features
python tools/tratar_csv_para_ia.py

# 3. PrÃ©-processar e normalizar
python tools/preprocessamento_ia.py

# 4. Treinar modelo
python model/main_train_model.py

# 5. Fazer inferÃªncia
python tools/inferencia_ddos.py data/pcap_convertido.csv data/resultados.csv
```

### 3. Interface web (Streamlit)
```bash
streamlit run app_inferencia.py
```

## ğŸ§  Features Padronizadas

O sistema agora usa **9 features consistentes**:

| Feature | DescriÃ§Ã£o | Uso para DDoS |
|---------|-----------|---------------|
| `flow_duration` | DuraÃ§Ã£o do fluxo (s) | Ataques rÃ¡pidos vs normais |
| `packet_rate` | Pacotes/segundo | Flood detection |
| `byte_rate` | Bytes/segundo | Amplification attacks |
| `src_ip_count` | IPs Ãºnicos de origem | Spoofing detection |
| `dst_ip_count` | IPs Ãºnicos de destino | Distributed attacks |
| `tcp_syn` | Flag SYN TCP | SYN flood detection |
| `length` | Tamanho do pacote | Pattern analysis |
| `dst_port` | Porta de destino | Service targeting |
| `protocol` | Protocolo (1=TCP, 2=UDP) | Protocol-based attacks |

## ğŸ“Š Labels Padronizados

```python
LABEL_MAPPING = {
    'Benign': 0,      # TrÃ¡fego normal
    'UDP-Flood': 1,   # Ataque UDP flood
    'SYN-Flood': 2,   # Ataque SYN flood  
    'HTTP-Flood': 3   # Ataque HTTP flood
}
```

## ğŸ”§ MÃ³dulos Principais

### `tools/feature_engineering.py`
- MÃ³dulo centralizado para todas as features
- Garante consistÃªncia entre treinamento e inferÃªncia
- ValidaÃ§Ã£o automÃ¡tica de dados

### `tools/pcap_to_csv.py` (corrigido)
- Extrai apenas dados brutos do PCAP
- NÃ£o calcula features (delegado para feature_engineering)

### `tools/tratar_csv_para_ia.py` (corrigido)
- Usa o pipeline padronizado de features
- Aplica regras consistentes de rotulaÃ§Ã£o

### `tools/preprocessamento_ia.py` (corrigido)
- NormalizaÃ§Ã£o padronizada
- Salva scaler e encoder consistentes
- ValidaÃ§Ã£o completa dos dados

### `tools/inferencia_ddos.py` (corrigido)
- Usa exato mesmo pipeline do treinamento
- Resultado limpo sem dados normalizados misturados
- Mapeamento consistente de labels

### `model/main_train_model.py` (corrigido)
- Treinamento com validaÃ§Ã£o robusta
- Grid search para otimizaÃ§Ã£o
- RelatÃ³rios detalhados de performance

## ğŸ“ˆ Melhorias Implementadas

1. **ValidaÃ§Ã£o automÃ¡tica** em todas as etapas
2. **Pipeline Ãºnico** para features (treino + inferÃªncia)
3. **Mapeamento consistente** de labels
4. **Metadata do modelo** salva automaticamente
5. **Testes automatizados** do pipeline completo
6. **Logs detalhados** para debugging
7. **Tratamento robusto** de valores invÃ¡lidos

## ğŸ” ValidaÃ§Ã£o dos Resultados

Execute para verificar se tudo estÃ¡ funcionando:
```bash
python test_pipeline.py
```

Ou verifique manualmente:
```bash
# Verificar features calculadas
head -5 data/dataset_final.csv

# Verificar dados normalizados  
head -5 data/dataset_preprocessado.csv

# Verificar resultados de inferÃªncia
head -5 data/resultados_inferencia.csv
```

## ğŸ“ Estrutura dos Arquivos

```
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ feature_engineering.py    # ğŸ†• MÃ³dulo centralizado
â”‚   â”œâ”€â”€ pcap_to_csv.py            # âœ… Corrigido
â”‚   â”œâ”€â”€ tratar_csv_para_ia.py     # âœ… Corrigido
â”‚   â”œâ”€â”€ preprocessamento_ia.py    # âœ… Corrigido
â”‚   â””â”€â”€ inferencia_ddos.py        # âœ… Corrigido
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ main_train_model.py       # âœ… Corrigido
â”‚   â”œâ”€â”€ ddos_model.pkl            # Modelo treinado
â”‚   â”œâ”€â”€ scaler.joblib            # Normalizador
â”‚   â”œâ”€â”€ encoder.joblib           # Codificador
â”‚   â””â”€â”€ model_metadata.json      # ğŸ†• Metadados
â”œâ”€â”€ test_pipeline.py              # ğŸ†• Testes automatizados
â””â”€â”€ README_CORRIGIDO.md          # ğŸ†• Esta documentaÃ§Ã£o
```

## âš¡ Performance Esperada

Com as correÃ§Ãµes implementadas:
- **ConsistÃªncia**: 100% entre treino e inferÃªncia
- **AcurÃ¡cia**: Melhor detecÃ§Ã£o devido a features corretas
- **Velocidade**: Pipeline otimizado
- **Confiabilidade**: ValidaÃ§Ã£o em todas as etapas

## ğŸ› Debugging

Se algo nÃ£o funcionar:

1. **Verifique dependÃªncias**: `pip list | grep -E "(pandas|sklearn|joblib)"`
2. **Execute testes**: `python test_pipeline.py`
3. **Verifique logs**: Mensagens detalhadas em cada etapa
4. **Valide dados**: Use `print_feature_summary()` do feature_engineering

## ğŸ“ Suporte

Os principais problemas foram corrigidos:
- âœ… Features consistentes
- âœ… Pipeline padronizado  
- âœ… ValidaÃ§Ã£o robusta
- âœ… Testes automatizados

O sistema agora estÃ¡ pronto para produÃ§Ã£o! ğŸš€
